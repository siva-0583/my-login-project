<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Install Cryostat with the new Helm chart</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/20/install-cryostat-new-helm-chart" /><author><name>Elliott Baron</name></author><id>c0362cda-ca71-4d5c-bee6-3b2e280eb079</id><updated>2022-06-20T07:00:00Z</updated><published>2022-06-20T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://cryostat.io/"&gt;Cryostat&lt;/a&gt; is a tool for managing &lt;a href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u"&gt;JDK Flight Recorder&lt;/a&gt; data on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. &lt;a href="articles/2022/06/08/9-awesome-updates-cryostat-21"&gt;Cryostat 2.1&lt;/a&gt; is now installable using a Helm chart. While the &lt;a href="https://catalog.redhat.com/software/operators/detail/60ee049a744684587e218ef5"&gt;Cryostat Operator&lt;/a&gt; is our preferred installation method for production environments, the Cryostat &lt;a href="https://developers.redhat.com/articles/2022/04/14/generate-helm-charts-your-java-application-using-jkube-part-1"&gt;Helm chart&lt;/a&gt; is a better choice for demo purposes. The Helm chart has a flexible design and requires few permissions to allow many users as needed.&lt;/p&gt; &lt;h2&gt;How to install the Cryostat Helm chart&lt;/h2&gt; &lt;p&gt;The Cryostat Helm chart is included by default in the &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; versions 4.8 and up. From the OpenShift developer console, click &lt;strong&gt;Add+&lt;/strong&gt;, and then select &lt;strong&gt;Helm Chart&lt;/strong&gt; from the developer catalog card. Search for &lt;strong&gt;Cryostat&lt;/strong&gt; and choose &lt;strong&gt;Install Helm Chart&lt;/strong&gt; (see Figure 1).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/cryostat-helm-1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/cryostat-helm-1.png?itok=UA-wz6Og" width="600" height="328" alt="Installing the Cryostat Helm Chart from the Developer Catalog" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Installing the Cryostat Helm Chart from the developer catalog. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;To install the Cryostat Helm chart on OpenShift 4.6-4.7, add the OpenShift Helm chart repository:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ helm repo add openshift-helm-charts https://charts.openshift.io/ $ helm install &lt;release_name&gt; cryostat&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Kubernetes users can install the community-supported version of the Helm chart from our GitHub repository:&lt;/p&gt; &lt;pre&gt; $ helm install &lt;release_name&gt; \ https://github.com/cryostatio/cryostat-helm/releases/download/v0.1.3/cryostat-0.1.3.tgz&lt;/pre&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Installing the Cryostat Helm chart creates the following objects:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A deployment containing Cryostat, Grafana, and a data source for Grafana.&lt;/li&gt; &lt;li&gt;Services for Cryostat and Grafana.&lt;/li&gt; &lt;li&gt;A service account, role, and role binding for Cryostat to use for discovering your applications.&lt;/li&gt; &lt;li&gt;By default on OpenShift, routes to expose the Cryostat and Grafana services outside of the clusters.&lt;/li&gt; &lt;li&gt;If enabled, ingresses to expose the Cryostat and Grafana services outside of the clusters.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There are a variety of configuration options to customize these objects. Our chart README contains a complete list of these options for &lt;a href="https://github.com/openshift-helm-charts/charts/blob/main/charts/redhat/redhat/cryostat/0.1.1/src/README.md"&gt;OpenShift&lt;/a&gt; and &lt;a href="https://github.com/cryostatio/cryostat-helm/blob/cryostat-v2.1/cryostat/README.md"&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Once the Helm chart is installed, it will prompt you to run additional commands which tell Cryostat’s components how to communicate with each other. The &lt;code&gt;ClusterIP&lt;/code&gt; service type with no route or ingress will illustrate how to use port forwarding with &lt;code&gt;kubectl&lt;/code&gt; or &lt;code&gt;oc&lt;/code&gt;. Run these commands in a terminal on your local machine with &lt;code&gt;kubectl&lt;/code&gt; or &lt;code&gt;oc&lt;/code&gt; logged into the cluster where you installed the Helm chart. Figure 2 illustrates an example of these instructions.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/cryostat-helm-2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/cryostat-helm-2.png?itok=hzrg70W3" width="600" height="328" alt="Post-install steps for the Cryostat Helm Chart shown in the Topology View" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Post-install steps for the Cryostat Helm Chart shown in the topology view. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;After running the commands listed in the &lt;strong&gt;Release notes&lt;/strong&gt; tab, the Cryostat deployment will roll out a new replica set. Once the new replica set is fully rolled out and the Cryostat deployment is available, click the &lt;strong&gt;Open URL&lt;/strong&gt; (&lt;img alt="Open URL" data-entity-type="file" data-entity-uuid="eb086c9e-381c-4c92-acf6-81ad5965bc04" src="https://developers.redhat.com/sites/default/files/inline-images/openurl.png" width="14" height="14" loading="lazy" /&gt;) button on the Cryostat deployment. This will bring you to the Cryostat web application served by the deployment.&lt;/p&gt; &lt;h2&gt;A comparison of the Cryostat Operator and the Cryostat Helm chart&lt;/h2&gt; &lt;p&gt;In the future, we plan to close the feature gap between the Cryostat Operator and Helm chart. This table compares their features:&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0" width="NaN"&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td width="NaN"&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;&lt;strong&gt;Cryostat Helm chart&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;&lt;strong&gt;Cryostat Operator&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;Grafana integration&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;span&gt;Access Cryostat using services&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;td class="text-align-center" width="NaN"&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;span&gt;Access Cryostat using ingresses or routes&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;End-to-end encryption&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; &lt;td class="text-align-center" width="NaN"&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/05/10/sso-all-cryostats-new-openshift-login-flow"&gt;Authentication&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td class="text-align-center" width="NaN"&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;Persistent storage&lt;/p&gt; &lt;/td&gt; &lt;td class="text-align-center" width="NaN"&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/05/25/eat-fewer-resources-cryostat-21-sidecar-reports"&gt;Report generator microservice&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td class="text-align-center" width="NaN"&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p class="text-align-center"&gt;X&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;Now there are two easy methods to install Cryostat into your cluster: the Cryostat Helm chart and the Cryostat Operator. You can obtain both of these for OpenShift from the &lt;a href="https://docs.openshift.com/container-platform/4.10/applications/creating_applications/odc-creating-applications-using-developer-perspective.html"&gt;Developer Catalog&lt;/a&gt; and &lt;a href="https://docs.openshift.com/container-platform/4.10/operators/user/olm-installing-operators-in-namespace.html"&gt;OperatorHub&lt;/a&gt;, respectively.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/20/install-cryostat-new-helm-chart" title="Install Cryostat with the new Helm chart"&gt;Install Cryostat with the new Helm chart&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Elliott Baron</dc:creator><dc:date>2022-06-20T07:00:00Z</dc:date></entry><entry><title>Learn about OpenShift command-line tools</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/16/learn-about-openshift-command-line-tools" /><author><name>Varsha Sharma</name></author><id>3b088a43-eb42-4132-b7cc-09be54bdceeb</id><updated>2022-06-16T07:00:00Z</updated><published>2022-06-16T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; simplifies application deployment, the management and monitoring of &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; clusters, and other developer tasks. The OpenShift tools, both command-line interface (CLI) and graphical user interface (GUI), cover many crucial deployment tasks. This article focuses on the &lt;code&gt;oc&lt;/code&gt; and &lt;code&gt;odo&lt;/code&gt; CLI commands, but touches on the GUIs as well.&lt;/p&gt; &lt;h2&gt;The oc client&lt;/h2&gt; &lt;p&gt;The OpenShift &lt;code&gt;oc&lt;/code&gt; command helps you develop, build, deploy, and run applications on an OpenShift or Kubernetes cluster. The command includes an &lt;code&gt;adm&lt;/code&gt; subcommand for administering the cluster.&lt;/p&gt; &lt;p&gt;&lt;code&gt;oc&lt;/code&gt; can be downloaded from the &lt;a href="https://developers.redhat.com/openshift/command-line-tools"&gt;help menu of your OpenShift web interface&lt;/a&gt;, from &lt;a href="https://github.com/openshift/origin/releases"&gt;OpenShift's GitHub releases page&lt;/a&gt;, or from the Red Hat web site after you create a Red Hat account. There are &lt;a href="https://access.redhat.com/downloads/content/290/ver=4.10/rhel---8/4.10.10/x86_64/product-software"&gt;binaries for many operating systems&lt;/a&gt;, including Linux, Microsoft Windows, and macOS.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;--help&lt;/code&gt; option (flag) offers an overview of the &lt;code&gt;oc&lt;/code&gt; command. This option can be also used with subcommands, which can help you build the right command in your early stages of use. For example, the following command displays options for the &lt;code&gt;whoami&lt;/code&gt; subcommand:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc whoami --help Show information about the current session The default options for this command will return the currently authenticated user name or an empty string. Other flags support returning the currently used token or the user context. Usage: oc whoami [flags] Examples: # Display the currently authenticated user oc whoami Options: --show-console=false: If true, print the current server's web console URL -c, --show-context=false: Print the current user context name --show-server=false: If true, print the current server's REST API URL -t, --show-token=false: Print the token the current session is using. This will return an error if you are using a different form of authentication. Use "oc options" for a list of global command-line options (applies to all commands). $ oc whoami --show-console https://console-openshift-console.apps.varsha.lab.upshift.rdu2.redhat.com&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Several more examples of &lt;code&gt;oc&lt;/code&gt; commands appear in the following subsections.&lt;/p&gt; &lt;h3&gt;View the console&lt;/h3&gt; &lt;p&gt;You can pull up the OpenShift console from the command line by entering:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;oc whoami --show-console&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Log in to an OpenShift cluster&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;login&lt;/code&gt; subcommand connects you to one of your clusters:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc login -u &lt;username&gt; -p &lt;password&gt; &lt;servername&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc login -u kubeadmin -p asdfghjkliuytr https://upi-o.varsha.lab.upshift.rdu2.redhat.com:6443&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Alternatively, you can use an access token to log in. Obtain a token by visiting:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;https://oauth-openshift.apps.varsha.lab.upshift.rdu2.redhat.com/oauth/token/request&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;A login using a token looks like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc login --token=sha256~vNVfZ0VuFK7SkveM_nGRFTS7nrfawCQnQ9FEPNScv-0 --server=https://api.varsha.lab.upshift.rdu2.redhat.com:6443&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Switch to a specific project&lt;/h3&gt; &lt;p&gt;Specify the name of your project with the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc project &lt;project_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;List existing projects&lt;/h3&gt; &lt;p&gt;You can view the projects in your account like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc project list $ oc projects&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Display the current project&lt;/h3&gt; &lt;p&gt;To see which project you are logged into, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc project&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Run applications&lt;/h3&gt; &lt;p&gt;Here are some useful commands to use with applications.&lt;/p&gt; &lt;p&gt;Execute a command on a particular pod:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc exec &lt;mypod&gt; -- &lt;command_to_execute_in_pod&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Start a remote shell so you can enter a series of commands on a pod:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc rsh &lt;pod_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Debug cluster activities on a pod:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc debug &lt;pod_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Frequently used commands&lt;/h3&gt; &lt;p&gt;Some more common activities are:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# See an overview of the current project oc status # -f, --follow=false: Specify if the logs should be streamed. oc logs -f &lt;pod_name&gt; # list all pods resource in ps output format oc get pods oc get po # list all resources in a namespace oc get all # Show details of a specific resource or group of resources. Print a detailed description of the selected resources, including related resources such as events or controllers. oc describe pod &lt;pod_name&gt; # List all services together in ps output format oc get services # To display output of yaml file of a resource oc get &lt;resource&gt; &lt;resource_name&gt; -o yaml # Delete all resources of the application oc delete all -l app=&lt;app_name&gt; # Delete all pods oc delete pod &lt;pod_name&gt; &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Scaling applications&lt;/h3&gt; &lt;p&gt;Autoscaling increases or decreases the number of pods in the cluster to meet demand for its service. OpenShift makes autoscaling easy. For instance, the following command creates an autoscaler for the specified deployment, replica set, stateful set, or replication controller:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc scale dc &lt;resource_name&gt; --replicas=&lt;count&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can also specify parameters for autoscaling. For instance, the following command allows OpenShift to scale the application between 2 and 4 pods with a target CPU utilization of 80%:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc autoscale deployment &lt;resource_name&gt; --min=2 --max=4 --cpu-percent=80%&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Deploy a ConfigMap&lt;/h3&gt; &lt;p&gt;A ConfigMap is a key-value listing used in many aspects of configuration. Normally, the ConfigMap is stored as YAML in a file and pushed to the cluster, as shown in the following command. The &lt;code&gt;--from-file&lt;/code&gt; option can be specified multiple times in a single command to create the ConfigMap from a combination of files:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc create configmap &lt;name&gt; --from-file=&lt;file_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Mount the ConfigMap into the pods via the deployment controller or deployment:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc set volume deployment/&lt;resource_name&gt; --add --name=&lt;config_map_volume&gt; -m &lt;mount_path&gt; -t configmap --configmap-name=&lt;name&gt; --default-mode='0777'&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Deploying a secret&lt;/h3&gt; &lt;p&gt;A secret is a key-value listing protected by encryption, and is used for sensitive data such as passwords. The following command creates a secret and mounts it as a volume to a deployment configuration:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc create secret generic &lt;secret_name&gt; --from-literal=username=myuser --from-file=&lt;file_name&gt; $ oc set volume dc/&lt;resource_name&gt; --add --name=&lt;secret_volume&gt; -m &lt;mount_path&gt; -t secret --secret-name=&lt;secret_name&gt; --default-mode='0755'&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;The odo client&lt;/h2&gt; &lt;p&gt;&lt;a href="https://odo.dev/docs/getting-started/features"&gt;odo&lt;/a&gt; (an abbreviation of &lt;em&gt;OpenShift do&lt;/em&gt;) is a developer-focused command that runs OpenShift applications in an expedited and automated manner. &lt;code&gt;odo&lt;/code&gt; reduces the developer's cognitive load. This command is for application developers who wish to deploy their applications to Kubernetes easily without spending a lot of time learning the &lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt; and Kubernetes procedures for deploying enterprise infrastructure. In contrast, &lt;code&gt;oc&lt;/code&gt; focuses on operations and requires a deeper understanding of Kubernetes and OpenShift concepts.&lt;/p&gt; &lt;p&gt;&lt;code&gt;odo&lt;/code&gt; can be installed from its &lt;a href="//odo.dev/docs/getting-started/installation"&gt;web page&lt;/a&gt; and has a &lt;a href="https://github.com/redhat-developer/odo"&gt;GitHub repository&lt;/a&gt; with documentation.&lt;/p&gt; &lt;h3&gt;Getting started with odo&lt;/h3&gt; &lt;p&gt;Here are a few commands to try in order to get familiar with &lt;code&gt;odo&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;You can create an application as follows. The final &lt;code&gt;push&lt;/code&gt; subcommand builds the application, pushes it to your cluster, and deploys it on OpenShift:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ git clone https://github.com/openshift/nodejs-ex $ cd nodejs-ex $ odo create nodejs $ odo push&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;watch&lt;/code&gt; subcommand tells &lt;code&gt;odo&lt;/code&gt; to automatically redeploy your application after edits:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; $ odo watch&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can edit your code in real time and watch as &lt;code&gt;odo&lt;/code&gt; automatically deploys your application.&lt;/p&gt; &lt;p&gt;You can create a URL where clients can send HTTP requests to your application as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ odo url create myurl $ odo push&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following commands give you more information about the cluster, such as logs or what components you've deployed:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ odo describe $ odo list $ odo log&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Visual Studio Code OpenShift Connector for Red Hat OpenShift: An odo GUI&lt;/h3&gt; &lt;p&gt;The &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-openshift-connector&amp;ssr=false#overview"&gt;OpenShift Connector extension&lt;/a&gt;, also known as the Visual Studio Code OpenShift Connector for Red Hat OpenShift, is a plug-in for the &lt;a href="https://developers.redhat.com/products/vscode-extensions/overview"&gt;VSCode IDE&lt;/a&gt; that interacts with Red Hat OpenShift clusters. Basically, the OpenShift Connector extension provides a GUI for &lt;code&gt;odo&lt;/code&gt; as well as &lt;code&gt;oc&lt;/code&gt;, combining groups of related commands into compact units. Developers can use the interface to accomplish complex tasks with minimal OpenShift experience.&lt;/p&gt; &lt;p&gt;To start with the connector, choose a predefined template, such as a Project, Application, or Service. The graphical interface can then build the resource and deploy it to your cluster as an OpenShift component. The OpenShift Connector can:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Create applications&lt;/li&gt; &lt;li&gt;Build applications&lt;/li&gt; &lt;li&gt;Debug applications&lt;/li&gt; &lt;li&gt;Deploy the applications directly to an OpenShift cluster&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The latest version of OpenShift Connector is available in the &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-openshift-connector"&gt;VS Code Marketplace&lt;/a&gt;. There are several options available for different environments, so you can use the interface directly on a laptop or &lt;a href="http://developers.redhat.com/products/codeready-containers"&gt;install it into a local OpenShift cluster&lt;/a&gt;. (There are limitations on Apple M1 hardware.)&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article should get you started on OpenShift using the command line or a GUI. You will grow in sophistication over time, and use the tools for such advanced tasks as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Gathering information from a cluster for debugging issues&lt;/li&gt; &lt;li&gt;Working directly with project source code&lt;/li&gt; &lt;li&gt;Managing project content when the web console is not accessible&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/16/learn-about-openshift-command-line-tools" title="Learn about OpenShift command-line tools"&gt;Learn about OpenShift command-line tools&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Varsha Sharma</dc:creator><dc:date>2022-06-16T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - June 16nd 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-06-16.html" /><category term="keycloak" /><category term="infinispan" /><category term="kogito" /><category term="jbang" /><category term="jakarta ee" /><category term="quarkus" /><category term="wildfly" /><category term="" /><author><name>Jason Porter</name><uri>https://www.jboss.org/people/jason-porter</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-06-16.html</id><updated>2022-06-16T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="keycloak, infinispan, kogito, jbang, jakarta ee, quarkus, wildfly,"&gt; &lt;h1&gt;This Week in JBoss - June 16nd 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Welcome back! Here’s some great content at the start of summer, and just like always, some releases!&lt;/p&gt; &lt;p&gt;We hope you have had a great week and are looking forward to summer.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases_releases_releases"&gt;Releases, releases, releases!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/06/keycloak-1801-released"&gt;Keycloak 18.0.1&lt;/a&gt; - The first bug fix release on the 18 branch is out. There are some minor enhancements and one new feature. Check the link for all the issues resolved in this release.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/06/kogito-1-22-1-released.html"&gt;Kogito 1.22.1&lt;/a&gt; - Another minor release, though it does have one small breaking change. Be sure to look at that and adjust your pom files accordingly.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_articles_blogs"&gt;Articles &amp;#38; Blogs&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://infinispan.org/blog/2022/06/14/infinispan-14-indexing-query-news"&gt;Infinispan 14 indexing and query news&lt;/a&gt; - With development of Infinispan 14 ongoing, Fabio Massimo Ercoli wanted to highlight some changes to indexing and searching. tl;dr: Hibernate annotations will be replaced with new Infinispan annotations. There are some other implications, so be sure to take a look.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/java/quick-jbang-scripting-with-intellij/"&gt;Quick JBang Scripting With IntelliJ Idea&lt;/a&gt; - Are you using IntelliJ Idea as your Java IDE? Take a look at the JBang integration plugin and what it allows you to do. You’ll be surprised at how much it can help.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/jboss-frameworks/resteasy/how-to-validate-jakarta-rest-endpoint-values/"&gt;How to validate Jakarta REST parameters&lt;/a&gt; - Using Bean Validation with JAX-RS is powerful. You can use built-in validations to ease development and extend to create your own custom validations for entities. No more having to write trivial &lt;code&gt;if&lt;/code&gt; statements to check if the provided data is valid.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/06/creating-tabs-using-dashbuilder%ef%bf%bc.html"&gt;Creating Tabs Using Dashbuilder&lt;/a&gt; - Nikhil Dewoolkar walks you through how to create tabs in Dashbuilder, a great alternative to some other dashboard projects.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_videos"&gt;Videos&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=UYSNM9Dy5M4"&gt;Introducing gRPC support in WildFly&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=ya8To5V1QUU"&gt;Quarkus Insights #92: Quinoa…​ Quarkus Modern UI with no hassles&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;Have a great week!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/jason-porter.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Jason Porter&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Jason Porter</dc:creator></entry><entry><title type="html">Struts2 and Tiles Tutorial</title><link rel="alternate" href="http://www.mastertheboss.com/web/struts-and-tiles/struts2-and-tiles-tutorial/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/web/struts-and-tiles/struts2-and-tiles-tutorial/</id><updated>2022-06-15T08:04:00Z</updated><content type="html">This updated tutorial shows how to build and deploy on WildFly a Struts 2 application powered by Apache Tiles, a template framework for Java Web applications. Pre-requisites: we recommend checking this tutorial to learn how to deploy Struts2 applications on WildFly: Getting started with Struts 2 on WildFly Apache Tiles allows authors to define page ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>OpenSSL 3.0: Dealing with a Turkish locale bug</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/15/openssl-30-dealing-turkish-locale-bug" /><author><name>Dmitry Belyavskiy</name></author><id>3fa8d903-6ede-4e1d-a4d0-b70ad62334bc</id><updated>2022-06-15T07:00:00Z</updated><published>2022-06-15T07:00:00Z</published><summary type="html">&lt;p&gt;Changes in libraries have a risk of breaking things in unpredictable places. Debugging a crash is usually simple. But recently, in the late stages of working on the &lt;code&gt;curl&lt;/code&gt; utility for &lt;a href="https://developers.redhat.com/products/rhel/download"&gt;Red Hat Enterprise Linux 9&lt;/a&gt;, I encountered a bug report that looked rather strange. In this article, I will discuss how this report led me to implement a localization bug fix during the late stages of RHEL 9 development.&lt;/p&gt; &lt;h2&gt;Why the curl utility with the Turkish locale failed&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;curl&lt;/code&gt; utility failed in a system configured with the Turkish locale (&lt;code&gt;tr_TR.utf8&lt;/code&gt;). The utility crashed in RHEL 9. It did not crash in Fedora 36; however, it failed to establish HTTPS connections.&lt;/p&gt; &lt;p&gt;It was easy to determine that the crash occurred when fetching one of the cipher algorithms—camellia-128. This was strange because the cipher was in the OpenSSL default provider, so it should be always available. The only suspicious thing was that the lookup name was in all caps: &lt;code&gt;CAMELLIA-128&lt;/code&gt;. However, OpenSSL makes a case-insensitive comparison for these fetches. The crash was related to a check that was absent in OpenSSL 3.0.1 (the base version in RHEL 9), which also explained the behavior difference between Fedora and RHEL.&lt;/p&gt; &lt;p&gt;Since the crash was locale-specific and presumably related to uppercase/lowercase comparison, I explored the case-insensitive comparison and the Turkish language variations as possible factors. Searching online yielded many resources, but this &lt;a href="http://www.i18nguy.com/unicode/turkish-i18n.html"&gt;article&lt;/a&gt; gives the best explanation. The alphabet used for English has a lowercase dotted i and an uppercase dotless I. But the Turkish alphabet has four letters for I: uppercase and lowercase dotted, and uppercase and lowercase dotless.&lt;/p&gt; &lt;p&gt;These additional Turkish letters change the relationship between the two letters English uses for I. Instead of the English case mapping of the lower dotted i to the upper dotless I, Turkish maps the lower dotted i to the upper dotted İ, and the lower dotless ı to the upper dotless I.&lt;/p&gt; &lt;p&gt;As it turns out, the change in the case rules for the letter &lt;em&gt;i&lt;/em&gt; frequently breaks software logic. As the article puts it, "Applications that have been internationalized are conditioned to easily accept new characters, collations, case rules, encodings, and other character-based properties and relationships. However, their design often does not anticipate that the properties or rules of English letters will change."&lt;/p&gt; &lt;p&gt;Armed with this knowledge, I set out to debug the utility for the Turkish locale.&lt;/p&gt; &lt;h2&gt;Match fails due to Turkish translations&lt;/h2&gt; &lt;p&gt;In a case-insensitive comparison in the Turkish locale, the uppercase name &lt;code&gt;CAMELLIA&lt;/code&gt; used for the lookup becomes lowercase with no dot: &lt;code&gt;camellıa.&lt;/code&gt; Since camellıa does not match the expected string (&lt;code&gt;camellia&lt;/code&gt;), the algorithm cannot be not found. Therefore, the omitted NULL check explains the crash.&lt;/p&gt; &lt;p&gt;The comparison uses &lt;code&gt;strcasecmp&lt;/code&gt; and &lt;code&gt;strncasecmp&lt;/code&gt; functions, which are locale-dependent. The &lt;code&gt;setlocale&lt;/code&gt; function will trigger the problem, but the command-line OpenSSL utility does not invoke that function, so the problem doesn't arise in the upstream test suite. &lt;code&gt;curl&lt;/code&gt; uses the system locale for this purpose. This issue did not occur in earlier versions of OpenSSL because it did not use a case-insensitive string comparison before version 3. Now, new versions use case-insensitive string comparisons more extensively.&lt;/p&gt; &lt;p&gt;So why was the connection not established even when the system did not crash? A debugging session revealed that the cause was another change between OpenSSL 1.1.1 and 3.0. The culprit was the so-called encoders/decoders mechanism for finding a relevant parser of ASN.1 structures. Encoders and decoders also identify objects by name. This time, there was a mismatch between &lt;code&gt;SubjectPublicKeyInfo&lt;/code&gt; and &lt;code&gt;subjectpublickeyinfo&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;If we want case insensitive comparison, we must always compare strings using a locale with predictable properties. Since algorithm names will never be internationalized, we can stop using locale-dependent &lt;code&gt;strcasecmp&lt;/code&gt; and &lt;code&gt;strncasecmp&lt;/code&gt; functions. We could compare strings byte-to-byte, but the profiling showed a significant performance slowdown. Luckily, POSIX implements a &lt;code&gt;strcasecmp_l&lt;/code&gt; function that accepts a specific locale object. If we pass a locale object matching the C locale to that function, we get the correct results.&lt;/p&gt; &lt;h3&gt;Adopt a debugging process early&lt;/h3&gt; &lt;p&gt;In theory, the rest of the process is simple: initialize a global object matching the C locale; use it everywhere in the OpenSSL code; free on shutdown. However, this leads to problems with the OpenSSL Federal Information Processing Standards (FIPS) provider. By design, FIPS requirements should not rely on a global object external to the module itself. This means we have to create another object inside the provider and manage it locally.&lt;/p&gt; &lt;p&gt;The resulting patch is one of the most invasive I have ever written. It changes approximately 80 files in the OpenSSL source tree and required serious testing. Global find-and-replace completes most of the changes. But some of them affect the core functionality of OpenSSL and, as mentioned before, touch the &lt;a href="https://developers.redhat.com/articles/2022/05/31/your-go-application-fips-compliant"&gt;FIPS module&lt;/a&gt;. In order for it to be accepted upstream, we had to build it to accommodate non-Linux platforms as well, and that required additional changes. We had a long discussion with the upstream developers on how to include the patch in the stable 3.0 series&lt;/p&gt; &lt;p&gt;During the course of preparing this article for publication, there were long discussions within upstream and the community. As a result, upstream got rid of the locale object and switched the implementation to byte-to-byte comparison. We are going to switch our implementation in the same way, but that won't happen soon.&lt;/p&gt; &lt;p&gt;You may come across internationalization-related issues everywhere, even if you think that you rely on plain ASCII. A wide client base and early adoption could help you find a particular issue early on when it is significantly less burdensome.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/15/openssl-30-dealing-turkish-locale-bug" title="OpenSSL 3.0: Dealing with a Turkish locale bug"&gt;OpenSSL 3.0: Dealing with a Turkish locale bug&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Dmitry Belyavskiy</dc:creator><dc:date>2022-06-15T07:00:00Z</dc:date></entry><entry><title type="html">Infinispan 14 indexing &amp;#38; query news</title><link rel="alternate" href="https://infinispan.org/blog/2022/06/14/infinispan-14-indexing-query-news" /><author><name>Fabio Massimo Ercoli</name></author><id>https://infinispan.org/blog/2022/06/14/infinispan-14-indexing-query-news</id><updated>2022-06-14T18:00:00Z</updated><content type="html">Dear Infinispan community, with the Infinispan 14 development release 03 we introduced some news on indexing and search capabilities. INFINISPAN INDEXING ANNOTATIONS Hibernate annotations are going to be replaced with the new Infinispan indexing annotations, that will be used in the same exact way for both embedded and remote queries. Here is an example of two annotated POJOs: Poem.java @Indexed public class Poem { private Author author; private String description; private Integer year; @Embedded(includeDepth = 2, structure = Structure.NESTED) public Author getAuthor() { return author; } @Text(projectable = true, analyzer = "whitespace", termVector = TermVector.WITH_OFFSETS) public String getDescription() { return description; } @Basic(projectable = true, sortable = true, indexNullAs = "1800") public Integer getYear() { return year; } } Author.java @Indexed public class Author { private String name; public Author(String name) { this.name = name; } @Keyword(projectable = true, sortable = true, normalizer = "lowercase", indexNullAs = "unnamed", norms = false) public String getName() { return name; } public void setName(String name) { this.name = name; } } Indexed fields without any special string/text transformation will be annotated as @Basic. If we need to apply a normalizer to a String field, we will opt for a @Keyword annotation. If we need to apply an analyzer to a String field, we will opt for a @Text annotation. The new annotations allow setting with the same annotation if the field should be sortable, or projectable, or its normalizer or its analyzer. However, not all the combinations will be possible, for instance the attribute sortable is not present on the @Text annotation, since an analyzed field cannot be used to sort the result set. indexNullAs attribute allow now to define a default value to use on index in case the corresponding entity values was null. Embedded indexes are defined using the @Embedded annotation, and it is possible to choose between the NESTED structure which preserves the original object relationship structure and FLATTENED structure which makes the leaf fields multi-valued fields of the parent entity. INDEX STARTUP MODE Sometimes indexes can be persistent and cache data not or vice versa, for those cases it can be useful to perform some operations to ensure the index will be consistent with data in the cache. We introduced the startup-mode configuration. Here is an example: &lt;distributed-cache&gt; &lt;indexing storage="filesystem" startup-mode="purge"&gt; &lt;!-- Additional indexing configuration goes here. --&gt; &lt;/indexing&gt; &lt;/distributed-cache&gt; With this configuration every time the cache is started, the indexes will be purged. Possible values are: purge, reindex, none and auto, with the latter Infinispan will decide if and in case which operation to perform according to how indexes ad cache data are configured. INDEX SCHEMA UPDATE This should be considered an advanced feature to be used only in case your model needs to be evolved time to time, and you need to continue to query your cache data without the aid of some data migrations or reindexing. For a comprehensive guide about when to use schema update instead of migrate or reindex the data please refer to the documentation. The command can be triggered from the HotRod remote administration API: remoteCacheManager.administration().updateIndexSchema(CACHE_NAME); or using the REST API, targeting the uri: POST .../v2/caches/{cacheName}/search/indexes?action=updateSchema or using the Infinispan cli by running update-schema on the runtime cache instance.</content><dc:creator>Fabio Massimo Ercoli</dc:creator></entry><entry><title>4 tips for achieving better security on Kubernetes</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/14/4-tips-achieving-better-security-kubernetes" /><author><name>Ajmal Kohgadai, Andy Oram</name></author><id>bbc59e5a-2379-48a8-8fa7-a93f4257cc56</id><updated>2022-06-14T07:00:00Z</updated><published>2022-06-14T07:00:00Z</published><summary type="html">&lt;p&gt;When security is ignored, organizations are putting at risk the core benefit of faster application development and releases. But security and agility do not have to be in contention.&lt;/p&gt; &lt;p&gt;A recent Red Hat survey with more than 300 respondents, covered in our &lt;a href="https://www.redhat.com/en/resources/state-kubernetes-security-report"&gt;2022 State of Kubernetes security report&lt;/a&gt;, identified the most pressing security needs and offered suggestions for putting your organization on track to protect security in &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; environments.&lt;/p&gt; &lt;p&gt;Our findings show that what happens in the build and deploy stages has a significant impact on security, as revealed by the prevalence of misconfigurations and vulnerabilities across organizations. Security, therefore, must shift left, embedded imperceptibly into &lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt; workflows instead of being "bolted on" when the application is about to be deployed into production.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Most of the material in this article comes from the Red Hat report, &lt;a href="https://www.redhat.com/en/resources/state-kubernetes-security-report"&gt;2022 State of Kubernetes security&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Top Kubernetes security tasks identified in the survey&lt;/h2&gt; &lt;p&gt;Organizations expect a security solution that protects containers and Kubernetes at every phase. Security starts at the earliest phases of development, such as &lt;a href="https://developers.redhat.com/articles/2022/03/07/manage-python-security-thoths-cloud-based-dependency-resolver"&gt;choosing secure third-party libraries&lt;/a&gt;, and extends to runtime monitoring and detection.&lt;/p&gt; &lt;p&gt;The methods used to protect applications span DevOps and security activities, underscoring the need for both in a &lt;a href="https://developers.redhat.com/topics/devsecops"&gt;DevSecOps&lt;/a&gt; approach in which the development, operations, and security teams collaborate.&lt;/p&gt; &lt;p&gt;The most important security tasks that respondents identified as "must-have" capabilities in Kubernetes (Figure 1) were:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Runtime threat detection and response (chosen by 69% of respondents)&lt;/li&gt; &lt;li&gt;Configuration management (chosen by 68% of respondents)&lt;/li&gt; &lt;li&gt;Image scanning and vulnerability management (chosen by 65% of respondents)&lt;/li&gt; &lt;/ul&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/top%20security%20tasks%20in%20kubernetes.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/top%20security%20tasks%20in%20kubernetes.png?itok=3WbCcPzo" width="1338" height="1016" alt="A cluster of three or four concerns topped the list of needed security capabilities." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A cluster of three or four concerns topped the list of needed security capabilities. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;When the respondents refer to configuration management, they are pointing out that security must currently be dropped into many different properties of YAML files with a variety of isolated parameters that are hard to learn and coordinate.&lt;/p&gt; &lt;h2&gt;Tips for starting on a stronger security course&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://www.redhat.com/en/resources/state-kubernetes-security-report"&gt;2022 State of Kubernetes security report&lt;/a&gt; ended with the following suggestions.&lt;/p&gt; &lt;h3&gt;Use Kubernetes-native security architectures and controls&lt;/h3&gt; &lt;p&gt;Kubernetes-native security uses the rich declarative data and native controls in Kubernetes to deliver several key security benefits. Analyzing the declarative data available in Kubernetes yields better security, with risk-based insights into configuration management, compliance, segmentation, and Kubernetes-specific vulnerabilities.&lt;/p&gt; &lt;p&gt;Using the same infrastructure and its controls for application development and security reduces the learning curve and supports faster analysis and troubleshooting. This consistent infrastructure also eliminates operational conflict by granting security the same automation and scalability advantages that Kubernetes extends to infrastructure.&lt;/p&gt; &lt;h3&gt;Start security early, but extend it across the full life cycle&lt;/h3&gt; &lt;p&gt;Security has long been viewed as a business inhibitor, especially by developers and DevOps teams whose core mandates are to deliver code fast. With containers and Kubernetes, security should become a business accelerator, by helping developers build strong security into their assets right from the start.&lt;/p&gt; &lt;p&gt;Look for a container and Kubernetes security platform that incorporates DevOps best practices and internal controls as part of its configuration checks. Such a platform should also employ tools that assess the security posture of the Kubernetes configuration itself, so that developers can focus on feature delivery. The open source &lt;a href="https://github.com/stackrox/kube-linter"&gt;KubeLinter&lt;/a&gt; tool picks up many security issues in Kubernetes configurations.&lt;/p&gt; &lt;h3&gt;Require portability across hybrid environments&lt;/h3&gt; &lt;p&gt;With most organizations deploying containers in both on-premises and public cloud environments (sometimes in multiple clouds), security must apply consistently wherever your assets are running. The common foundation is Kubernetes, so make Kubernetes your source of truth, your point of enforcement, and your universal visibility layer for consistent security. Managed Kubernetes services can quicken your organization’s adoption of Kubernetes, but be careful about getting locked into cloud provider-specific tooling and services.&lt;/p&gt; &lt;h3&gt;Transform the developer into a security user by building a bridge between DevOps and security&lt;/h3&gt; &lt;p&gt;Given that most organizations expect DevOps to run container security platforms, your security tooling must help bridge security and DevOps. To be effective, the platform must have security controls that make sense in a containerized, Kubernetes-based environment. It should also assess risk appropriately. Telling a developer to fix all discovered vulnerabilities that have a Common Vulnerability Scoring System (CVSS) score of 7 or higher is inefficient. Instead, you can improve security significantly by identifying the three deployments that are exposed to the most severe vulnerabilities and showing the developers why these deployments are at risk.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Learning the best practices outlined in this article is a good first step toward improving your application's security. The speed with which new containerized applications are built and deployed as &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt; requires security automation in developer workflows. Developers shouldn’t have to slow down to run manual security checks. Organizations should deploy automated security in a DevOps fashion, using security tools that enable an open hybrid strategy for application security. Learn more about how &lt;a href="https://www.redhat.com/en/resources/advanced-cluster-security-for-kubernetes-datasheet"&gt;Red Hat Advanced Cluster Security for Kubernetes&lt;/a&gt; can provide developers with the security guardrails to help them automate DevSecOps in their pipelines.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/14/4-tips-achieving-better-security-kubernetes" title="4 tips for achieving better security on Kubernetes"&gt;4 tips for achieving better security on Kubernetes&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ajmal Kohgadai, Andy Oram</dc:creator><dc:date>2022-06-14T07:00:00Z</dc:date></entry><entry><title>Use OpenVINO to convert speech to text</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/13/use-openvino-convert-speech-text" /><author><name>Sean Pryor</name></author><id>2dc726d3-1f06-4051-b51f-115f84829bcf</id><updated>2022-06-13T17:48:00Z</updated><published>2022-06-13T17:48:00Z</published><summary type="html">&lt;p&gt;Speech to text is one of the most common use cases for artificial intelligence. It's used all over to allow easier human interaction. Phone tree automation is a common use case.&lt;/p&gt; &lt;p&gt;This article will walk you through a speech-to-text example using OpenVINO, an open-source toolkit for optimizing and deploying AI inference. This example is a variant of the OpenVINO speech-to-text demo notebook which can be found in &lt;a href="https://github.com/openvinotoolkit/openvino_notebooks/blob/main/notebooks/211-speech-to-text/211-speech-to-text.ipynb"&gt;OpenVINO's GitHub repository&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;What is QuartzNet?&lt;/h2&gt; &lt;p&gt;QuartzNet is a variant of a Jasper network that performs speech-to-text translation.&lt;/p&gt; &lt;p&gt;The inputs to the network are a series of units called &lt;em&gt;mel spectrograms.&lt;/em&gt; These are a way of representing audio data that involves several steps of processing.&lt;/p&gt; &lt;p&gt;First, the raw audio signal is divided into overlapping sections, and then a Fourier transformation is applied to them converting from signals over time to frequencies. Then the log scale of the frequency is compared to the amplitude to form a spectrogram.&lt;/p&gt; &lt;p&gt;Finally, the spectrogram's domain is changed to the &lt;a href="https://www.sfu.ca/sonic-studio-webdav/handbook/Mel.html"&gt;mel scale&lt;/a&gt;, which is a frequency scale that better differentiates between the ranges of frequency that human speech and hearing cover, forming a mel spectrogram.&lt;/p&gt; &lt;p&gt;For more on mel spectrograms, read &lt;a href="https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53"&gt;Leland Roberts' article on the subject&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;OpenVINO toolkit&lt;/h2&gt; &lt;p&gt;OpenVINO is a framework for optimizing models, as well as an optimized inference server. It allows you to perform several optimizations:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Quantization&lt;/strong&gt;: Reducing floating point precision to increase processing speed. INT8 can be orders of magnitude faster than FP16 with similar levels of precision in some cases.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Accuracy-aware quantization&lt;/strong&gt;: Automated quantization that preserves a user-specified level of accuracy.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Pruning and sparsity&lt;/strong&gt;: Reducing unnecessary complexity of the model. For example, this could involve removing layers that aren't contributing much to the overall result or weights that are extremely small.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Operation fusing&lt;/strong&gt;: Combining several model layers into one. This gives equivalent accuracy but can run significantly faster on Intel hardware given the use of specialized instructions&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;On &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/overview"&gt;Red Hat OpenShift Data Science&lt;/a&gt;, the default deployment is done on Intel hardware, meaning there is no additional setup required.&lt;/p&gt; &lt;p&gt;The notebook we'll be looking at in this article covers downloading a QuartzNet model, converting it to OpenVINO Intermediate Representation (IR), serving it via OpenVINO Model Server, sending mel spectrograms of English-language audio for inference, and decoding the results using a simple algorithm. Note that this is an example; some parts, such as the decoding algorithm, could be improved if one were to adapt this for a production use case.&lt;/p&gt; &lt;p&gt;The OpenVINO Model Server (OVMS) is an Intel-optimized model server, which allows a user to serve multiple models, keep track of generations of models, and lets users update them without downtime.&lt;/p&gt; &lt;h2&gt;Download the QuartzNet model&lt;/h2&gt; &lt;p&gt;OpenVINO has its &lt;a href="https://github.com/openvinotoolkit/open_model_zoo"&gt;own model zoo&lt;/a&gt; where you can browse and download pre-compiled and pre-trained models from.&lt;/p&gt; &lt;p&gt;For this demo, we will download an ONNX-format QuartzNet model. The ONNX (Open Neural Network Exchange Format) format is easily portable for exchanging models. It allows a user to package a model from a range of frameworks easily into a single file, and is easy to reinstantiate from that single file allowing for great portability. OVMS will later convert this format into its own IR for optimization.&lt;/p&gt; &lt;p&gt;The notebook, we first start with a few bits of boilerplate by setting up the paths:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; model_folder = "model" download_folder = "output" data_folder = "data" precision = "FP16" model_name = "quartznet-15x5-en" &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;&lt;code&gt;omz_downloader&lt;/code&gt; automatically creates a directory structure and downloads the selected model. This step is skipped if the model is already downloaded. The selected model comes from the public directory, which means it must be converted into Intermediate Representation (IR).&lt;/p&gt; &lt;pre&gt; &lt;code&gt; # Check if model is already downloaded in download directory path_to_model_weights = Path(f'{download_folder}/public/{model_name}/models') downloaded_model_file = list(path_to_model_weights.glob('*.pth')) if not path_to_model_weights.is_dir() or len(downloaded_model_file) == 0: download_command = f"omz_downloader --name {model_name} --output_dir {download_folder} --precision {precision}" ! $download_command &lt;/code&gt; &lt;/pre&gt; &lt;h2&gt;Convert the model to IR&lt;/h2&gt; &lt;p&gt;Next, we need to convert the model from ONNX format into OpenVINO IR format, which consists of three files.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;XML:&lt;/strong&gt; The XML file describes the layers of the network, their dimensions, and parameters. It also describes the data flow. However, it does not store the actual weights; those are instead references to the bin file, which contains the weights and other large values.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Bin: &lt;/strong&gt;This file contains the large constant values like layer weights and other things that detail the state of the model.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Mapping:&lt;/strong&gt; This file contains some additional metadata detailing things like the IO between layers.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A more detailed explanation is available in the &lt;a href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_IR_and_opsets.html"&gt;OpenVINO docs&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;code&gt;omz_converter&lt;/code&gt; converts the pre-trained PyTorch model to the ONNX model format, which is further converted to the OpenVINO IR format. Both stages of conversion are handled by calling &lt;code&gt;omz_converter&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; # Check if model is already converted in model directory path_to_converted_weights = Path(f'{model_folder}/public/{model_name}/{precision}/{model_name}.bin') if not path_to_converted_weights.is_file(): convert_command = f"omz_converter --name {model_name} --precisions {precision} --download_dir {download_folder} --output_dir {model_folder}" ! $convert_command &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;In the end, you should have the following files:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;quartznet-15x5-en.bin&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;quartznet-15x5-en.mapping&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;quartznet-15x5-en.xml&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Upload the model and directory structure to S3&lt;/h2&gt; &lt;p&gt;In OVMS, the model server looks for the following directory structure:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; tree models/ models/ ├── model1 │ ├── 1 │ │ ├── ir_model.bin │ │ └── ir_model.xml │ └── 2 │ ├── ir_model.bin │ └── ir_model.xml └── model2 │ └── 1 │ ├── ir_model.bin │ ├── ir_model.xml │ └── mapping_config.json └── model3 └── 1 └── model.onnx &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;You can find more about the model repository directory structure in the &lt;a href="https://docs.openvino.ai/latest/ovms_docs_models_repository.html"&gt;OpenVINO docs&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The next step is uploading the OpenVINO IR files to S3. This demo assumes that you have a local S3 set up in advance; setting that up is beyond the scope of this demo. If you don't have access to a real S3 bucket, there are alternatives like Ceph RadosGW or Google Storage, which are also supported by OVMS.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; import boto3 access_key = 'S3_ACCESS_KEY' # &lt;- Replace with actual key secret_key = 'S3_SECRET_KEY' # &lt;- Replace with actual key s3 = boto3.client('s3', endpoint_url='ENDPOINT_URL', # &lt;- This is only necessary when using Ceph RadosGW aws_access_key_id=access_key, aws_secret_access_key=secret_key,) s3.upload_file('model/public/quartznet-15x5-en/FP16/quartznet-15x5-en.bin', 'openvino-quartznet', '1/quartznet-15x5-en.bin') s3.upload_file('model/public/quartznet-15x5-en/FP16/quartznet-15x5-en.mapping', 'openvino-quartznet', '1/quartznet-15x5-en.mapping') s3.upload_file('model/public/quartznet-15x5-en/FP16/quartznet-15x5-en.xml', 'openvino-quartznet', '1/quartznet-15x5-en.xml') &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;This gives us the following structure in s3:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; # tree s3://openvino-quartznet/ └── 1 ├── quartznet-15x5-en.bin ├── quartznet-15x5-en.mapping └── quartznet-15x5-en.xml &lt;/code&gt; &lt;/pre&gt; &lt;h2&gt;Create an OVMS instance&lt;/h2&gt; &lt;p&gt;Now that we have uploaded the model to S3, we can create an instance of the OpenVINO Model Server to serve the model. Intel has an OVMS Operator that will allow users to easily provision an OVMS instance. Here's an example custom resource for the Operator:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; kind: ModelServer apiVersion: intel.com/v1alpha1 metadata: name: openvino-quartznet-model-server namespace: your-project-namespace spec: image_name: &gt;- registry.connect.redhat.com/intel/openvino-model-server@sha256:f670aa3dc014b8786e554b8a3bb7e2e8475744d588e5e72d554660b74430a8c5 deployment_parameters: replicas: 1 resources: limits: cpu: '4' memory: '4Gi' requests: cpu: '4' memory: '4Gi' service_parameters: grpc_port: 8080 rest_port: 8081 models_settings: single_model_mode: true config_configmap_name: '' model_config: '' model_name: 'quartznet' # This is the name the model is served with model_path: 's3://openvino-quartznet/' # This URL path to where the model repository was stored earlier nireq: 0 plugin_config: '{"CPU_THROUGHPUT_STREAMS":1}' batch_size: '' shape: '(1, 64, 176)' # This is needed due to the notebook having a slightly different input shape than the default. OVMS handles this conversion automatically model_version_policy: '{"latest": { "num_versions":1 }}' layout: '' target_device: CPU is_stateful: false idle_sequence_cleanup: false low_latency_transformation: true max_sequence_number: 0 server_settings: file_system_poll_wait_seconds: 0 sequence_cleaner_poll_wait_minutes: 0 log_level: INFO grpc_workers: 1 rest_workers: 0 models_repository: storage_type: S3 https_proxy: '' http_proxy: '' models_host_path: '' models_volume_claim: '' aws_secret_access_key: 'S3_SECRET_KEY' # Replace with actual key aws_access_key_id: 'S3_ACCESS_KEY' # Replace with actual key aws_region: '' s3_compat_api_endpoint: 'ENDPOINT_URL' # This is only necessary when using Ceph RadosGW gcp_creds_secret_name: '' azure_storage_connection_string: '' &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Once the server finishes initializing, the model will be available on both gRPC and HTTP endpoints.&lt;/p&gt; &lt;h3&gt;ovmsclient&lt;/h3&gt; &lt;p&gt;For a simple, lightweight client, &lt;code&gt;ovmsclient&lt;/code&gt; is an easy way to interact with an OVMS server. The client maintains an underlying gRPC client to OVMS and provides several convenience features. For starters, the following code allows users to connect to and query the input and output parameters of the model:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; import ovmsclient import librosa import numpy as np import scipy client = ovmsclient.make_grpc_client("openvino-quartznet-model-server.default.svc.cluster.local:8080") model_metadata = client.get_model_metadata(model_name="quartznet") print(model_metadata) {'model_version': 1, 'inputs': {'audio_signal': {'shape': [1, 64, 176], 'dtype': 'DT_FLOAT'}}, 'outputs': {'output': {'shape': [1, 88, 29], 'dtype': 'DT_FLOAT'}}} &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;We can see that the shape is the input shape defined in the CR above.&lt;/p&gt; &lt;h3&gt;Convert audio data to mel&lt;/h3&gt; &lt;p&gt;In order to perform inference, raw audio data must be converted to the mel spectrograms we discussed above. The code below performs this conversion:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; # First load the audio data, in this case a clip of English audio with the speaker saying "from the edge to the cloud" audio, sampling_rate = librosa.load(path=f'data/edge_to_cloud.ogg', sr=16000) # This first function converts the audio to mel spectrograms. This has specific window sizing and a hardcoded sampling rate. A different algorithm could be implemented if user needs differ. def audio_to_mel(audio, sampling_rate): assert sampling_rate == 16000, "Only 16 KHz audio supported" preemph = 0.97 preemphased = np.concatenate([audio[:1], audio[1:] - preemph * audio[:-1].astype(np.float32)]) # Calculate window length win_length = round(sampling_rate * 0.02) # Based on previously calculated window length run short-time Fourier transform spec = np.abs(librosa.core.spectrum.stft(preemphased, n_fft=512, hop_length=round(sampling_rate * 0.01), win_length=win_length, center=True, window=scipy.signal.windows.hann(win_length), pad_mode='reflect')) # Create mel filter-bank, produce transformation matrix to project current values onto Mel-frequency bins mel_basis = librosa.filters.mel(sampling_rate, 512, n_mels=64, fmin=0.0, fmax=8000.0, htk=False) return mel_basis, spec # This function changes the mel spectrograms by converting them to a logarithmic scale, normalizing them, and adding padding to make processing easier. Note that this padding ensures the input shape is consistent, and matches the (1, 64, 176) we supplied as the input shape when creating the model server instance. def mel_to_input(mel_basis, spec, padding=16): # Convert to logarithmic scale log_melspectrum = np.log(np.dot(mel_basis, np.power(spec, 2)) + 2 ** -24) # Normalize output normalized = (log_melspectrum - log_melspectrum.mean(1)[:, None]) / (log_melspectrum.std(1)[:, None] + 1e-5) # Calculate padding remainder = normalized.shape[1] % padding if remainder != 0: return np.pad(normalized, ((0, 0), (0, padding - remainder)))[None] return normalized[None] mel_basis, spec = audio_to_mel(audio=audio.flatten(), sampling_rate=sampling_rate) audio = mel_to_input(mel_basis=mel_basis, spec=spec) # The inference server requires a dict that has the following formatting. The input key is the same 'audio_signal' that was returned by the metadata call above inputs = {'audio_signal': audio} # If we look at the shape with the included padding, it's the same shape as the model is expecting now print(audio.shape) (1, 64, 176) &lt;/code&gt; &lt;/pre&gt; &lt;h3&gt;Inference example&lt;/h3&gt; &lt;p&gt;The final step is to actually perform the inference. This involves using &lt;code&gt;ovmsclient&lt;/code&gt; to make the inference call, as well as decoding the results. As noted above, the decoding step in this example is a simpler example than would be expected in a production environment and is only provided for demo purposes. In particular, it only decodes each letter as it changes, meaning that words that require repeated letters wouldn't work. In our example, the words contain no double letters, and so will work fine, but please be aware of the example's limitations.&lt;/p&gt; &lt;p&gt;At the end, we'll have an iterator containing predictions for each time, and the index of each corresponding to a letter in the alphabet array.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; character_probabilities = client.predict(inputs = inputs, model_name="quartznet") alphabet = " abcdefghijklmnopqrstuvwxyz'~" # These correspond to the 29 different outputs, the value being the probability of each character. We take the maximum prediction as the highest probability for a given letter. character_probabilities = next(iter(character_probabilities)) # Remove unnecessary dimension (we are doing inference in batches of 1) character_probabilities = np.squeeze(character_probabilities) # Run argmax to pick most possible symbols character_probabilities = np.argmax(character_probabilities, axis=1) def ctc_greedy_decode(predictions): previous_letter_id = blank_id = len(alphabet) - 1 transcription = list() for letter_index in predictions: if previous_letter_id != letter_index != blank_id: transcription.append(alphabet[letter_index]) previous_letter_id = letter_index return ''.join(transcription) transcription = ctc_greedy_decode(character_probabilities) print(transcription) from the edge to the cloud &lt;/code&gt; &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you've seen an end-to-end example setup for voice transcription using OpenVINO. This has many applications, from note taking to chatbots to voice search. Using OpenVINO, the model can easily be optimized for any target hardware footprint as well, allowing it to be used anywhere from the edge to the cloud.&lt;/p&gt; &lt;p&gt;For a deeper dive, check out the &lt;a href="https://github.com/Xaenalt/OpenVINO-DevCON-Speech-to-text"&gt;complete code for this notebook example&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/13/use-openvino-convert-speech-text" title="Use OpenVINO to convert speech to text"&gt;Use OpenVINO to convert speech to text&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Sean Pryor</dc:creator><dc:date>2022-06-13T17:48:00Z</dc:date></entry><entry><title type="html">Quick JBang Scripting With IntelliJ Idea</title><link rel="alternate" href="http://www.mastertheboss.com/java/quick-jbang-scripting-with-intellij/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/quick-jbang-scripting-with-intellij/</id><updated>2022-06-13T07:29:26Z</updated><content type="html">This quick article shows how to install and use JBang’s IntelliJ Idea plugin to create JBang projects and scripts in no time. Firstly, to get started quickly with JBang, we recommend having a look at this article: JBang: Create Java scripts like a pro Next, let’s see how to install JBang Plugin on IntelliJ Idea ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>A quick way to translate physical addresses into virtual ones</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/13/quick-way-translate-physical-addresses-virtual-ones" /><author><name>Noah Sanci</name></author><id>6f155b24-4a0a-4743-a319-ad07b799c29e</id><updated>2022-06-13T07:00:00Z</updated><published>2022-06-13T07:00:00Z</published><summary type="html">&lt;p&gt;Recently, I have been working on enabling cooperation between SystemTap (a kernel profiling tool) and gprof (a tool that makes graphs from program profiles). This exercise has given me insight into meaningful topics only briefly touched upon at my university, such as kernel space, user space, and virtual memory. But these concepts are fundamental to the proper and safe execution of programs on any modern operating system. The trade off is some address translation when viewing memory from kernel space versus user space. In this article, you'll see how that translation can be handled.&lt;/p&gt; &lt;h2&gt;A quick dive into user and kernel address spaces&lt;/h2&gt; &lt;p&gt;User space and kernel space are kept separate in all modern OSes. This separation is an essential layer of security between information essential to the operation of the machine and the applications on that machine.&lt;/p&gt; &lt;p&gt;As the term suggests, &lt;em&gt;user process address space&lt;/em&gt; is the area where user-run processes are stored and store information. &lt;em&gt;Text pages&lt;/em&gt; are a portion of the process address space that stores the program’s code.&lt;/p&gt; &lt;p&gt;Consider a simple calculator program, of the sort installed on most OSes. If you ran this calculator program with the expression &lt;code&gt;5+5&lt;/code&gt; and a web browser at the same time without any preventative measures, the browser might be able to access the mathematical expression located in the calculator’s address space and change it to a different expression, such as &lt;code&gt;6+6&lt;/code&gt;. Common sense dictates that this should not occur except under very unique circumstances. The operating system provides the program separation that the user desires by giving each process its own isolated address space.&lt;/p&gt; &lt;p&gt;The kernel address space is the realm of the kernel code and information that may be useful to other programs, such as user input/output and network data. Kernel space information is generally inaccessible except through functions known as &lt;em&gt;system calls.&lt;/em&gt;&lt;/p&gt; &lt;h2&gt;How virtual memory works&lt;/h2&gt; &lt;p&gt;&lt;em&gt;Virtual memory&lt;/em&gt; is a simple convenience in the form of an abstraction. Without virtual memory, applications would need to manage their physical memory space, coordinating with every other process running on the computer. Virtual memory leaves that management to the kernel by creating maps that allow translation between virtual and physical memory. Applications use virtual memory, and the kernel’s memory management unit (MMU) uses physical memory. The MMU is the mapping hardware that translates virtual memory addresses to physical memory addresses.&lt;/p&gt; &lt;p&gt;To understand how virtual memory works, suppose there are two running programs: a calculator with the expression &lt;code&gt;5+5&lt;/code&gt; and an internet browser. The calculator may have the expression &lt;code&gt;5+5&lt;/code&gt; stored in the address &lt;code&gt;0xdeadbeef&lt;/code&gt;, and the browser could store any of its data, such as an IP address, in &lt;code&gt;0xdeadbeef&lt;/code&gt; as well. Why doesn't one piece of information overwrite the other? The addresses where the programs are storing their data are located in virtual memory, and they refer to different locations in physical memory. Although the virtual addresses are the same, the OS handles the physical addresses, which are completely different.&lt;/p&gt; &lt;p&gt;The OS may also take a page from a process and write it to disk to make space for another process page, resulting in two operations at the same physical address.&lt;/p&gt; &lt;h2&gt;SystemTap and gprof cooperation&lt;/h2&gt; &lt;p&gt;I have been working on leveraging the data collected by SystemTap and outputting it into a gprof-readable format. SystemTap profiles programs that use shared libraries. The problem is that SystemTap can load those libraries anywhere in virtual memory. It must relativize their addresses and process them later.&lt;/p&gt; &lt;p&gt;&lt;code&gt;umodaddr()&lt;/code&gt;, shown in the listing below, was created for the purpose of this translation:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;function umodaddr:long (address:long) %{ /* pragma:vma */ long vm_start = -1; stap_find_vma_map_info(current, STAP_ARG_address, &amp;vm_start, NULL, NULL, NULL,NULL); if(vm_start == -1) STAP_ERROR("umodaddr 0x%llx unknown\n ", STAP_ARG_address); STAP_RETURN(STAP_ARG_address - vm_start); %} &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;This function takes the virtual address of the called function, found in &lt;code&gt;STAP_ARG_address&lt;/code&gt;, and returns its offset from the beginning of the virtual memory. This function becomes a tool to ensure that SystemTap outputs addresses relative to the beginning of their virtual memory, enabling compatibility with gprof.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;With this translation complete, a SystemTap script can use these translated addresses to create a file that can be interpreted by gprof. This file will be of the gmon.out format, so it will internally contain a histogram. A script can then automatically invoke gprof on all of these files, giving us the ability to leverage gprof's functionality to inspect a process's activity.&lt;/p&gt; &lt;p&gt;Understanding how virtual memory works made it possible to combine the extremely low-level capabilities of SystemTap with the informative functionality of gprof. This will allow users to gain insight into where precisely a program spends time and contribute to solving time-sensitive issues.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/13/quick-way-translate-physical-addresses-virtual-ones" title="A quick way to translate physical addresses into virtual ones"&gt;A quick way to translate physical addresses into virtual ones&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Noah Sanci</dc:creator><dc:date>2022-06-13T07:00:00Z</dc:date></entry></feed>
